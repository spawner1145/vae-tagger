# VAE-Tagger

### å®‰è£…ä¾èµ–

```bash
git clone https://github.com/spawner1145/vae-tagger.git
cd vae-tagger
pip install -r requirements.txt
```

### 1. å‡†å¤‡æ•°æ®

```bash
# åˆ›å»ºæµ‹è¯•æ•°æ®é›† (å¯é€‰,å…·ä½“æ•°æ®é›†æ ¼å¼åœ¨ä¸‹é¢)
python create_test_dataset.py --source_json your_data.json --output_dir test_dataset --test_ratio 0.1
```

### 2. è®­ç»ƒæ¨¡å‹

**é€‰é¡¹ A: ç®€å•ç«¯åˆ°ç«¯è®­ç»ƒ (æ¨è)**
```bash
python train_full.py \
    # è¿™è¾¹çš„vaeçš„safetensorså’Œjsonæ–‡ä»¶å¯ä»¥åœ¨ https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main/vae ä¸‹è½½ï¼Œå¼€å¤´ä¸‰ä¸ªéƒ½æ˜¯å¯é€‰å‚æ•°
    --vae_checkpoint diffusion_pytorch_model.safetensors \
    --vae_config_path diffusers_vae_config.json \
    --decoder_checkpoint decoder_checkpoint/best_pytorch_model.bin \
    --json_path test_dataset/data.json \
    --tags_csv_path test_dataset/tags.csv \
    --output_dir full_model \
    --resolution 1024 \
    --train_batch_size 2 \
    --num_epochs 10 \
    --use_bucketing \
    --base_resolution 512 \
    --max_resolution 1024 \
    --bucket_step 64 \
    --use_adaptive_weights \
    --use_focal_loss \
    --learning_rate 0.0001 \
    --attention_heads 8
```

**é€‰é¡¹ B: åˆ†æ­¥è®­ç»ƒ**
```bash
# æ­¥éª¤ 1: è®­ç»ƒ VAE
python train_vae.py \
    --vae_checkpoint diffusion_pytorch_model.safetensors \
    --vae_config_path diffusers_vae_config.json \
    --json_path test_dataset/data.json \
    --tags_csv_path test_dataset/tags.csv \
    --output_dir vae_checkpoint \
    --resolution 1024 \
    --train_batch_size 4 \
    --num_epochs 20 \
    --use_bucketing \
    --base_resolution 512 \
    --max_resolution 1024 \
    --bucket_step 64 \
    --mixed_precision fp16 \
    --learning_rate 0.0001 \
    --use_simplified_vae_loss

# æ­¥éª¤ 2: è®­ç»ƒè§£ç å™¨
python train_decoder.py \
    --vae_checkpoint diffusion_pytorch_model.safetensors \
    --vae_config_path diffusers_vae_config.json \
    --json_path test_dataset/data.json \
    --tags_csv_path test_dataset/tags.csv \
    --output_dir decoder_checkpoint \
    --resolution 1024 \
    --train_batch_size 4 \
    --num_epochs 15 \
    --use_bucketing \
    --base_resolution 512 \
    --max_resolution 1024 \
    --bucket_step 64 \
    --use_focal_loss \
    --use_class_balanced \
    --learning_rate 0.001 \
    --attention_heads 8
```

### 3. è¿è¡Œæ¨ç†

```bash
# å•å¼ å›¾åƒæ¨ç†
python infer_full.py \
    --image_path path/to/image.jpg \
    --vae_checkpoint models/vae/pytorch_model.bin \
    --decoder_checkpoint models/decoder/pytorch_model.bin \
    --tags_csv_path your_tags.csv

# æ‰¹é‡æ¨ç†
python infer_batch.sh /path/to/images/ models/ output/
```

## ğŸ“ æ•°æ®é›†æ ¼å¼

VAE-Tagger éœ€è¦ä¸¤ä¸ªæ ¸å¿ƒæ–‡ä»¶æ¥å®šä¹‰æ•°æ®é›†ï¼š

### 1. å›¾åƒå…ƒæ•°æ®æ–‡ä»¶ (JSON æ ¼å¼)

è¿™æ˜¯ä¸€ä¸ªåŒ…å«å›¾åƒä¿¡æ¯å’Œæ ‡ç­¾çš„ JSON æ–‡ä»¶ã€‚**æ³¨æ„**: æœ¬é¡¹ç›®æä¾›çš„ `create_test_dataset.py` åªæ˜¯åˆ›å»ºæµ‹è¯•æ•°æ®é›†çš„ä¸€ç§æ–¹æ³•ï¼Œä½ å¯ä»¥æ‰‹åŠ¨åˆ›å»ºç¬¦åˆä»¥ä¸‹æ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼š

```json
{
    "path/to/image1.jpg": "cat:1.0, outdoor:0.9, nature:0.8",
    "path/to/image2.png": "dog:1.0, indoor:0.95",
    "path/to/image3.jpg": "cat:1.0, dog:0.8, outdoor:0.7, large:1.0"
}
```

**æ ¼å¼è¯´æ˜:**
- **é”®**: å›¾åƒæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰
- **å€¼**: ç”¨é€—å·åˆ†éš”çš„æ ‡ç­¾å­—ç¬¦ä¸²ï¼ŒåŒ…å«ç½®ä¿¡åº¦åˆ†æ•°
- **æ ‡ç­¾æ ¼å¼**: `æ ‡ç­¾å:ç½®ä¿¡åº¦åˆ†æ•°`
- **ç½®ä¿¡åº¦**: 0.0-1.0ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼ˆå¯é€‰ï¼Œçœç•¥æ—¶é»˜è®¤ä¸º1.0ï¼‰

### 2. æ ‡ç­¾å®šä¹‰æ–‡ä»¶ (CSV æ ¼å¼)

å®šä¹‰æ‰€æœ‰å¯èƒ½æ ‡ç­¾çš„ CSV æ–‡ä»¶ï¼š

```csv
name,count
cat,150
dog,120
outdoor,200
indoor,180
nature,90
large,75
medium,85
small,60
```

**å­—æ®µè¯´æ˜:**
- `name`: æ ‡ç­¾åç§° (å¿…é¡»ä¸ JSON æ–‡ä»¶ä¸­çš„æ ‡ç­¾åŒ¹é…)
- `count`: è¯¥æ ‡ç­¾åœ¨æ•°æ®é›†ä¸­å‡ºç°çš„æ¬¡æ•° (ç”¨äºç»Ÿè®¡)

### 3. æ•°æ®é›†åˆ›å»ºæŒ‡å—

#### æ‰‹åŠ¨åˆ›å»ºæ•°æ®é›†çš„æ­¥éª¤:

1. **å‡†å¤‡å›¾åƒæ–‡ä»¶**: å°†æ‰€æœ‰å›¾åƒæ”¾åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªç›®å½•ä¸­
2. **åˆ›å»ºæ ‡ç­¾å®šä¹‰**: åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾å¹¶åˆ†é…ID
3. **æ ‡æ³¨å›¾åƒ**: ä¸ºæ¯å¼ å›¾åƒåˆ†é…ç›¸åº”çš„æ ‡ç­¾
4. **ç”ŸæˆJSONæ–‡ä»¶**: æŒ‰ç…§ä¸Šè¿°æ ¼å¼åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶

#### ç¤ºä¾‹ç›®å½•ç»“æ„(å…¶å®æ— æ‰€è°“ï¼ŒcsvæŒ‡å‘æ‰€æœ‰å‡ºç°çš„tagï¼ŒjsonæŒ‡å‘æ‰€æœ‰å›¾ç‰‡è·¯å¾„å°±è¡Œ):
```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ cats/
â”‚   â”‚   â”œâ”€â”€ cat001.jpg
â”‚   â”‚   â””â”€â”€ cat002.png
â”‚   â”œâ”€â”€ dogs/
â”‚   â”‚   â”œâ”€â”€ dog001.jpg
â”‚   â”‚   â””â”€â”€ dog002.jpg
â”‚   â””â”€â”€ mixed/
â”‚       â””â”€â”€ animal001.jpg
â”œâ”€â”€ metadata.json
â””â”€â”€ tags.csv
```

## ğŸ¯ è®­ç»ƒæ¨¡å¼

VAE-Tagger æ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥ä»¥é€‚åº”ä¸åŒä½¿ç”¨åœºæ™¯ï¼š

### 1. ç®€åŒ–æ¨¡å¼ (é»˜è®¤)
```bash
python train_full.py --use_simplified_loss
```
- **é€‚ç”¨äº**: å¿«é€ŸåŸå‹å¼€å‘ï¼Œèµ„æºæœ‰é™çš„ç¯å¢ƒ
- **ç‰¹æ€§**: ç®€åŒ–çš„æŸå¤±è®¡ç®—ï¼Œæ›´å¿«çš„è®­ç»ƒé€Ÿåº¦
- **æŸå¤±ç»„æˆ**: åˆ†ç±»æŸå¤± + ä¸‰å…ƒç»„å­¦ä¹ 

### 2. æ ‡å‡†æ¨¡å¼
```bash
python train_full.py --use_focal_loss --use_class_balanced
```
- **é€‚ç”¨äº**: ç”Ÿäº§ç¯å¢ƒè®­ç»ƒï¼Œä¸å¹³è¡¡æ•°æ®é›†
- **ç‰¹æ€§**: é«˜çº§æŸå¤±å‡½æ•°ï¼Œç¨³å¥çš„ä¼˜åŒ–
- **æŸå¤±ç»„æˆ**: Focal Loss + ç±»å¹³è¡¡ + è¯­ä¹‰å­¦ä¹ 

### 3. ç ”ç©¶æ¨¡å¼
```bash
python train_full.py --use_adaptive_weights --use_focal_loss
```
- **é€‚ç”¨äº**: å®éªŒç ”ç©¶ï¼Œè¿½æ±‚æœ€ä½³æ€§èƒ½
- **ç‰¹æ€§**: è‡ªé€‚åº”ä¼˜åŒ–ï¼Œå®Œæ•´çš„VAEè®­ç»ƒ
- **æŸå¤±ç»„æˆ**: æ‰€æœ‰æŸå¤± + è‡ªåŠ¨æƒé‡å¹³è¡¡

## ğŸ“Š æŸå¤±å‡½æ•°æŒ‡å—

### å¯ç”¨æŸå¤±å‡½æ•°

| æŸå¤±ç±»å‹ | ä½¿ç”¨åœºæ™¯ | å‘½ä»¤æ ‡å¿— |
|---------|---------|---------|
| **Focal Loss** | ä¸å¹³è¡¡æ•°æ®é›† | `--use_focal_loss` |
| **ç±»å¹³è¡¡æŸå¤±** | é•¿å°¾åˆ†å¸ƒ | `--use_class_balanced` |
| **ä¸‰å…ƒç»„æŸå¤±** | è¯­ä¹‰ç›¸ä¼¼æ€§ | é»˜è®¤å¯ç”¨ |
| **å¯¹æ¯”æŸå¤±** | ä¸‰å…ƒç»„æŸå¤±çš„æ›¿ä»£ | ä¿®æ”¹é…ç½® |
| **è‡ªé€‚åº”æƒé‡** | è‡ªåŠ¨ä¼˜åŒ– | `--use_adaptive_weights` |

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

### æ ¸å¿ƒç»„ä»¶
- **FLUX VAE ç¼–ç å™¨**: é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ç¼–ç å™¨ï¼Œæä¾›ç¨³å¥çš„å›¾åƒç‰¹å¾
- **è¯­ä¹‰è§£ç å™¨**: åŸºäºå¤šå±‚æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†ç±»å™¨  
- **ä¸‰å…ƒç»„å­¦ä¹ **: ç”¨äºè¯­ä¹‰ç›¸ä¼¼æ€§çš„å¯¹æ¯”å­¦ä¹ 
- **è‡ªé€‚åº”æŸå¤±**: è‡ªå¹³è¡¡ä¼˜åŒ–

### æ¶æ„æµç¨‹
```
å›¾åƒ â†’ FLUX VAE â†’ æ½œåœ¨ç‰¹å¾ â†’ æ³¨æ„åŠ›è§£ç å™¨ â†’ æ ‡ç­¾é¢„æµ‹
  â†“                â†“
é‡æ„ â† è¯­ä¹‰å­¦ä¹  â† åˆ†ç±»æŸå¤±
```

## ğŸ“š API å‚è€ƒ

### æ ¸å¿ƒè®­ç»ƒè„šæœ¬

#### `train_full.py`
å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒæµæ°´çº¿ã€‚

**å…³é”®å‚æ•°:**
- `--use_simplified_loss`: å¯ç”¨ç®€åŒ–è®­ç»ƒæ¨¡å¼
- `--use_focal_loss`: å¯¹ä¸å¹³è¡¡æ•°æ®åº”ç”¨Focal Loss
- `--use_adaptive_weights`: å¯ç”¨è‡ªåŠ¨æŸå¤±å¹³è¡¡
- `--similarity_type`: é€‰æ‹©'cosine'æˆ–'euclidean'ç›¸ä¼¼åº¦

#### `train_vae.py`
å¸¦ä¸‰å…ƒç»„å­¦ä¹ çš„VAEä¸“ç”¨è®­ç»ƒã€‚

**å…³é”®å‚æ•°:**
- `--use_simplified_vae_loss`: ç®€åŒ–VAEè®­ç»ƒ(ä»…KLç›‘æ§)
- `--kl_weight`: KLæ•£åº¦æŸå¤±æƒé‡(é»˜è®¤: 0.01)
- `--triplet_weight`: ä¸‰å…ƒç»„æŸå¤±æƒé‡(é»˜è®¤: 1.0)

#### `train_decoder.py`
åˆ†ç±»è§£ç å™¨è®­ç»ƒã€‚

**å…³é”®å‚æ•°:**
- `--use_focal_loss`: å¯ç”¨Focal Loss
- `--use_class_balanced`: å¯ç”¨ç±»å¹³è¡¡æŸå¤±
- `--focal_alpha`, `--focal_gamma`: Focal Losså‚æ•°

### å®ç”¨å·¥å…·è„šæœ¬

- `validate_data.py`: æ•°æ®é›†éªŒè¯å’Œç»Ÿè®¡
- `evaluation.py`: å…¨é¢çš„æ¨¡å‹è¯„ä¼°
- `analyze_resolutions.py`: æ•°æ®é›†åˆ†è¾¨ç‡åˆ†æ
- `vae_reconstruction_test.py`: VAEé‡æ„å¯è§†åŒ–

### æ¨ç†è„šæœ¬

- `infer_full.py`: å•å›¾åƒæ¨ç†
- `infer_vae.py`: ä»…VAEæ¨ç†
- `infer_batch.sh`: æ‰¹å¤„ç†è„šæœ¬

## ğŸ”§ é…ç½®

### æ¨¡å‹é…ç½® (`vae_config.json`)
```json
{
  "sample_size": 512,
  "in_channels": 3,
  "out_channels": 3,
  "latent_channels": 16,
  "use_quant_conv": false,
  "scaling_factor": 0.3611,
  "shift_factor": 0.1159
}
```

### è®­ç»ƒé…ç½®
å…³é”®å‚æ•°å¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®æ–‡ä»¶è°ƒæ•´ï¼š

- **å­¦ä¹ ç‡**: `--learning_rate` (é»˜è®¤: 1e-4)
- **æ‰¹å¤§å°**: `--train_batch_size` (é»˜è®¤: 4)
- **æŸå¤±æƒé‡**: `--reconstruction_weight`, `--kl_weight` ç­‰
- **ä¼˜åŒ–è®¾ç½®**: `--lr_scheduler_type`, `--max_grad_norm`
